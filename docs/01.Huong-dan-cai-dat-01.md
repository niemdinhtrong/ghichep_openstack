# Hướng dẫn cài đặt cinder-backup mô hình đơn giản

## Mô hình

![](../images/01/OPS-cinder-backup-nfs-3node.png)

**Mô tả**: Mô hình cài đặt là mô hình đơn giản nhất. Cinder-volume và cinder-backup được cài chung trên node controller

## Phân hoạch IP

![](../images/01/01.png)

## Cài đặt

### 1. Thiết lập ban đầu

#### 1.1 Cài đặt trên controller

Cài đặt các gói cơ bản

```
yum update -y
yum install epel-release -y
yum update -y 
yum install -y wget byobu git vim
```

Thiết lập hostname

```
hostnamectl set-hostname controller
bash
```

Cấu hình IP

```
nmcli con modify eth0 ipv4.addresses 10.10.35.122/24
nmcli con modify eth0 ipv4.gateway 10.10.35.1
nmcli con modify eth0 ipv4.dns 8.8.8.8
nmcli con modify eth0 ipv4.method manual
nmcli con modify eth0 connection.autoconnect yes

nmcli con modify eth1 ipv4.addresses 10.10.31.122/24
nmcli con modify eth1 ipv4.method manual
nmcli con modify eth1 connection.autoconnect yes


nmcli con modify eth2 ipv4.addresses 10.10.32.122/24
nmcli con modify eth2 ipv4.method manual
nmcli con modify eth2 connection.autoconnect yes
```

Sửa file host

```
echo "127.0.0.1 localhost" > /etc/hosts
echo "10.10.35.122 controller" >> /etc/hosts
echo "10.10.35.123 compute1" >> /etc/hosts
echo "10.10.35.124 compute2" >> /etc/hosts
```

Tắt selinux

```
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
setenforce 0
systemctl disable firewalld
systemctl stop firewalld
systemctl stop NetworkManager
systemctl disable NetworkManager
systemctl enable network
systemctl start network
```

#### 1.2 Cài đặt trên compute1

Cài đặt các gói cơ bản

```
yum update -y
yum install epel-release -y
yum update -y 
yum install -y wget byobu git vim
```

Thiết lập hostname

```
hostnamectl set-hostname compute1
bash
```

Cấu hình IP

```
nmcli con modify eth0 ipv4.addresses 10.10.35.123/24
nmcli con modify eth0 ipv4.gateway 10.10.35.1
nmcli con modify eth0 ipv4.dns 8.8.8.8
nmcli con modify eth0 ipv4.method manual
nmcli con modify eth0 connection.autoconnect yes

nmcli con modify eth1 ipv4.addresses 10.10.31.123/24
nmcli con modify eth1 ipv4.method manual
nmcli con modify eth1 connection.autoconnect yes


nmcli con modify eth2 ipv4.addresses 10.10.32.123/24
nmcli con modify eth2 ipv4.method manual
nmcli con modify eth2 connection.autoconnect yes
```

Sửa file host

```
echo "127.0.0.1 localhost" > /etc/hosts
echo "10.10.35.122 controller" >> /etc/hosts
echo "10.10.35.123 compute1" >> /etc/hosts
echo "10.10.35.124 compute2" >> /etc/hosts
```

Tắt selinux

```
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
setenforce 0
systemctl disable firewalld
systemctl stop firewalld
systemctl stop NetworkManager
systemctl disable NetworkManager
systemctl enable network
systemctl start network
```

#### 1.3 Cài đặt trên compute2

Cài đặt các gói cơ bản

```
yum update -y
yum install epel-release -y
yum update -y 
yum install -y wget byobu git vim
```

Thiết lập hostname

```
hostnamectl set-hostname compute2
bash
```

Cấu hình IP

```
nmcli con modify eth0 ipv4.addresses 10.10.35.124/24
nmcli con modify eth0 ipv4.gateway 10.10.35.1
nmcli con modify eth0 ipv4.dns 8.8.8.8
nmcli con modify eth0 ipv4.method manual
nmcli con modify eth0 connection.autoconnect yes

nmcli con modify eth1 ipv4.addresses 10.10.31.124/24
nmcli con modify eth1 ipv4.method manual
nmcli con modify eth1 connection.autoconnect yes


nmcli con modify eth2 ipv4.addresses 10.10.32.124/24
nmcli con modify eth2 ipv4.method manual
nmcli con modify eth2 connection.autoconnect yes
```

Sửa file host

```
echo "127.0.0.1 localhost" > /etc/hosts
echo "10.10.35.122 controller" >> /etc/hosts
echo "10.10.35.123 compute1" >> /etc/hosts
echo "10.10.35.124 compute2" >> /etc/hosts
```

Tắt selinux

```
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
setenforce 0
systemctl disable firewalld
systemctl stop firewalld
systemctl stop NetworkManager
systemctl disable NetworkManager
systemctl enable network
systemctl start network
```

### 2. Cài đặt Openstack

#### 2.1 Cài đặt package OPS cho cả 3 node

```
yum -y install centos-release-openstack-train
yum -y upgrade
yum -y install crudini wget vim
yum -y install python-openstackclient openstack-selinux python2-PyMySQL
yum -y update
```

#### 2.2 Cài đặt NTP

**2.2.1 Cài NTP trên controller**

Cấu hình cho NTP server để tất cả các node đồng bộ thời gian với controller

Cài đặt chrony

```
yum -y install chrony
```

Sao lưu cấu hình NTP

```
cp /etc/chrony.conf /etc/chrony.conf.bak
```

Bạn có thể cấu hình thời gian cho controller hoặc đồng bộ từ 1 server NTP (trên internet hoặc local).

Set timezone

```
timedatectl set-timezone Asia/Ho_Chi_Minh
```

Sửa file cấu hình

```
sed -i s'/0.centos.pool.ntp.org/10.10.35.150/'g /etc/chrony.conf
sed -i s'/server 1.centos.pool.ntp.org iburst/#server 1.centos.pool.ntp.org iburst/'g /etc/chrony.conf
sed -i s'/server 2.centos.pool.ntp.org iburst/#server 2.centos.pool.ntp.org iburst/'g /etc/chrony.conf
sed -i s'/server 3.centos.pool.ntp.org iburst/#server 3.centos.pool.ntp.org iburst/'g /etc/chrony.conf
```

Cho phép các node được phép đồng bộ với controller theo dải mạng management

```
sed -i s'|#allow 192.168.0.0/16|allow 10.10.35.0/24|'g /etc/chrony.conf
```

Khởi động lại chrony

```
systemctl restart chronyd
systemctl enable chronyd
```

**2.2.2 Cài NTP trên 2 node compute**

> Thực hiện cài đặt trên cả 2 node compute còn lại

Cài đặt chrony

```
yum -y install chrony
```

Sao lưu cấu hình NTP

```
cp /etc/chrony.conf /etc/chrony.conf.bak
```

Set timezone

```
timedatectl set-timezone Asia/Ho_Chi_Minh
```

Sửa file cấu hình

```
sed -i s'/0.centos.pool.ntp.org/controller/'g /etc/chrony.conf
sed -i s'/server 1.centos.pool.ntp.org iburst/#server 1.centos.pool.ntp.org iburst/'g /etc/chrony.conf
sed -i s'/server 2.centos.pool.ntp.org iburst/#server 2.centos.pool.ntp.org iburst/'g /etc/chrony.conf
sed -i s'/server 3.centos.pool.ntp.org iburst/#server 3.centos.pool.ntp.org iburst/'g /etc/chrony.conf
```

Khởi động lại chrony

```
systemctl restart chronyd
systemctl enable chronyd
```

#### 2.3 Cài đặt memcache trên controller

Cài đặt

```
yum -y install memcached python-memcached
```

Backup cấu hình

```
cp /etc/sysconfig/memcached /etc/sysconfig/memcached.bak
```

Khai báo địa chỉ IP để các node có thể truy cập

```
sed -i "s/-l 127.0.0.1,::1/-l 127.0.0.1,::1,10.10.35.122/g" /etc/sysconfig/memcached
```

Khởi động lại memcache

```
systemctl enable memcached.service
systemctl restart memcached.service
```

#### 2.4 Cài đặt MariaDB trên node controller

Cài đặt MariaDB

```
yum -y install mariadb mariadb-server python2-PyMySQL
```

Tạo và sửa file cấu hình

```
cat <<EOF> /etc/my.cnf.d/openstack.cnf
[mysqld]
bind-address = 10.10.35.122

default-storage-engine = innodb
innodb_file_per_table = on
max_connections = 4096
collation-server = utf8_general_ci
character-set-server = utf8
EOF
```

Khởi động lại MariaDB

```
systemctl enable mariadb.service
systemctl start mariadb.service
```

Khai báo mật khẩu

```
mysql_secure_installation
```

Đặt mật khẩu cho user root. Ở đây tôi đặt là `Welcome123`

Phân quyền truy cập từ xa cho user root

```
mysql -uroot -pWelcome123

GRANT ALL PRIVILEGES ON *.* TO 'root'@'10.10.35.122' IDENTIFIED BY 'Welcome123' WITH GRANT OPTION;

FLUSH PRIVILEGES;

DROP USER 'root'@'::1';

exit
```

#### 2.5 Cấu hình rabbitmq trên controller

Cài đặt rabbitmq

```
yum -y install rabbitmq-server
```

Khởi động rabbitmq

```
systemctl enable rabbitmq-server.service
systemctl start rabbitmq-server.service
```

Khai báo plugin cho rabbitmq

```
rabbitmq-plugins enable rabbitmq_management
```

Cấu hình trang quản lý rabbitmq trên UI

```
curl -O http://localhost:15672/cli/rabbitmqadmin
chmod a+x rabbitmqadmin
mv rabbitmqadmin /usr/sbin/
```

Tạo user vào mật khẩu

```
rabbitmqctl add_user openstack Welcome123
```

Cấp quyền cho user vừa tạo

```
rabbitmqctl set_permissions openstack ".*" ".*" ".*"
rabbitmqctl set_user_tags openstack administrator
rabbitmqadmin list users
```

#### 2.6 Cài đặt Etcd trên node controller

Cài đặt `etcd`

```
yum -y install etcd
```

Backup file cấu hình

```
cp /etc/etcd/etcd.conf /etc/etcd/etcd.conf.bak
```

Sửa file cấu hình

```
sed -i '/ETCD_DATA_DIR=/cETCD_DATA_DIR="/var/lib/etcd/default.etcd"' /etc/etcd/etcd.conf
sed -i '/ETCD_LISTEN_PEER_URLS=/cETCD_LISTEN_PEER_URLS="http://10.10.35.122:2380"' /etc/etcd/etcd.conf
sed -i '/ETCD_LISTEN_CLIENT_URLS=/cETCD_LISTEN_CLIENT_URLS="http://10.10.35.122:2379"' /etc/etcd/etcd.conf
sed -i '/ETCD_NAME=/cETCD_NAME="controller"' /etc/etcd/etcd.conf
sed -i '/ETCD_INITIAL_ADVERTISE_PEER_URLS=/cETCD_INITIAL_ADVERTISE_PEER_URLS="http://10.10.35.122:2380"' /etc/etcd/etcd.conf
sed -i '/ETCD_ADVERTISE_CLIENT_URLS=/cETCD_ADVERTISE_CLIENT_URLS="http://10.10.35.122:2379"' /etc/etcd/etcd.conf
sed -i '/ETCD_INITIAL_CLUSTER=/cETCD_INITIAL_CLUSTER="controller=http://10.10.35.122:2380"' /etc/etcd/etcd.conf
sed -i '/ETCD_INITIAL_CLUSTER_TOKEN=/cETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster-01"' /etc/etcd/etcd.conf
sed -i '/ETCD_INITIAL_CLUSTER_STATE=/cETCD_INITIAL_CLUSTER_STATE="new"' /etc/etcd/etcd.conf
```

Khởi động `etcd`

```
systemctl enable etcd
systemctl restart etcd
```

Kiểm tra dịch vụ

```
systemctl status etcd
```

#### 2.7 Cài đặt và cấu hình Keystone trên node controller

Tạo database và user

```
mysql -uroot -pWelcome123
CREATE DATABASE keystone;
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'10.10.35.122' IDENTIFIED BY 'Welcome123';
FLUSH PRIVILEGES;
exit
```

Cài đặt keystone

```
yum -y install openstack-keystone httpd mod_wsgi
```

Sao lưu cấu hình keystone

```
cp /etc/keystone/keystone.conf /etc/keystone/keystone.conf.bak
```

Sửa cấu hình keystone

```
crudini --set /etc/keystone/keystone.conf database connection mysql+pymysql://keystone:Welcome123@10.10.35.122/keystone
crudini --set /etc/keystone/keystone.conf token provider fernet
```

Phân quyền cho file cấu hình keystone

```
chown root:keystone /etc/keystone/keystone.conf
```

Import database keystone

```
su -s /bin/sh -c "keystone-manage db_sync" keystone
```

Sinh các file cho fernet

```
keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
```

Thiết lập boottrap cho keystone

```
keystone-manage bootstrap --bootstrap-password Welcome123 \
--bootstrap-admin-url http://10.10.35.122:5000/v3/ \
--bootstrap-internal-url http://10.10.35.122:5000/v3/ \
--bootstrap-public-url http://10.10.35.122:5000/v3/ \
--bootstrap-region-id RegionOne
```

Keystone sẽ sử dụng httpd để chạy service, các request vào keystone sẽ thông qua httpd. Do vậy cần cấu hình httpd để keystone sử dụng.
Sửa cấu hình httpd, mở file /etc/httpd/conf/httpd.conf để sửa dòng 95 thành như sau

```
ServerName controller
```

Tạo liên kết cho file /usr/share/keystone/wsgi-keystone.conf

```
ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/
```

Khởi động httpd

```
systemctl enable httpd.service
systemctl start httpd.service
```

Kiểm tra lại service của httpd

```
systemctl status httpd.service
```

Tạo file biến môi trường cho keystone

```
cat << EOF > /root/admin-openrc
export OS_USERNAME=admin
export OS_PASSWORD=Welcome123
export OS_PROJECT_NAME=admin
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_DOMAIN_NAME=Default
export OS_AUTH_URL=http://10.10.31.166:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
EOF
```

Thực thi biến môi trường

```
source /root/admin-openrc
```

Kiểm tra lại hoạt động của keystone

```
openstack token issue
```

Màn hình xuất hiện như bên dưới là OK.

```
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field      | Value                                                                                                                                                                                   |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| expires    | 2020-06-24T05:54:20+0000                                                                                                                                                                |
| id         | gAAAAABe8tx8KcGgaSULfkvS5w_8r2coWZ5s6zyK8PZ6cebj7mgT9aktjd-uw-XvcEdZmV2gW4eDfDJpVy4PmtWXEQTzsIPrQtng_yTOtN9vs9VzLAP0GfXSsSGSEubwihd3qXmLiLwuuFul9gemyVGcJ20UwE46Z4qCtLrdqeqbACpcjgRGFpE |
| project_id | 46161aba23f04e8d86f0ae79910a5c1d                                                                                                                                                        |
| user_id    | e4dbcd43e62a42798852f1f3637930bd                                                                                                                                                        |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

Khai báo user `demo` và project `demo`

```
openstack project create service --domain default --description "Service Project" 
openstack project create demo --domain default --description "Demo Project" 
openstack user create demo --domain default --password Welcome123
openstack role create user
openstack role add --project demo --user demo user
```

#### 2.8 Cài đặt Glance trên controller

Tạo database cho glance

```
mysql -uroot -pWelcome123
CREATE DATABASE glance;
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'10.10.35.122' IDENTIFIED BY 'Welcome123';
FLUSH PRIVILEGES;
exit
```

Thực thi biến môi trường

```
source /root/admin-openrc
```

Tạo user, project cho glance

```
openstack user create  glance --domain default --password Welcome123
openstack role add --project service --user glance admin
openstack service create --name glance --description "OpenStack Image" image
openstack endpoint create --region RegionOne image public http://10.10.35.122:9292
openstack endpoint create --region RegionOne image internal http://10.10.35.122:9292
openstack endpoint create --region RegionOne image admin http://10.10.35.122:9292
```

Cài đặt glance

```
yum install -y openstack-glance
yum install -y MySQL-python
yum install -y python-devel
```

Sao lưu file cấu hình glance

```
cp /etc/glance/glance-api.conf /etc/glance/glance-api.conf.bak
```

Cấu hình glance

```
crudini --set /etc/glance/glance-api.conf database connection  mysql+pymysql://glance:Welcome123@10.10.35.122/glance

crudini --set /etc/glance/glance-api.conf keystone_authtoken www_authenticate_uri http://10.10.35.122:5000
crudini --set /etc/glance/glance-api.conf keystone_authtoken auth_url  http://10.10.35.122:5000
crudini --set /etc/glance/glance-api.conf keystone_authtoken memcached_servers 10.10.35.122:11211
crudini --set /etc/glance/glance-api.conf keystone_authtoken auth_type password 
crudini --set /etc/glance/glance-api.conf keystone_authtoken project_domain_name Default
crudini --set /etc/glance/glance-api.conf keystone_authtoken user_domain_name Default
crudini --set /etc/glance/glance-api.conf keystone_authtoken project_name service
crudini --set /etc/glance/glance-api.conf keystone_authtoken username glance
crudini --set /etc/glance/glance-api.conf keystone_authtoken password Welcome123

crudini --set /etc/glance/glance-api.conf paste_deploy flavor keystone

crudini --set /etc/glance/glance-api.conf glance_store stores file,http
crudini --set /etc/glance/glance-api.conf glance_store default_store file
crudini --set /etc/glance/glance-api.conf glance_store filesystem_store_datadir /var/lib/glance/images/
```

Import database cho glance

```
su -s /bin/sh -c "glance-manage db_sync" glance
```

Khởi động glance

```
systemctl enable openstack-glance-api.service
systemctl start openstack-glance-api.service
```

Tải image và import vào glance

```
wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img
openstack image create "cirros" --file cirros-0.4.0-x86_64-disk.img --disk-format qcow2 --container-format bare --public
```

Kiểm tra images

```
openstack image list
```

Danh sách các image đã được up hiện ra tương tự sau:

```
+--------------------------------------+--------+--------+
| ID                                   | Name   | Status |
+--------------------------------------+--------+--------+
| f6c2a88b-c725-4662-a3ab-30197af7d14b | cirros | active |
+--------------------------------------+--------+--------+
```

#### 2.9 Cài đặt Placement trên controller

Tạo database, user, mật khẩu cho placement

```
mysql -uroot -pWelcome123 
CREATE DATABASE placement;
GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'10.10.35.122' IDENTIFIED BY 'Welcome123';
FLUSH PRIVILEGES;
exit
```

Thực thi biến môi trường

```
source /root/admin-openrc
```

Tạo service, gán quyền, enpoint cho placement.

```
openstack user create  placement --domain default --password Welcome123
openstack role add --project service --user placement admin
openstack service create --name placement --description "Placement API" placement
openstack endpoint create --region RegionOne placement public http://10.10.35.122:8778
openstack endpoint create --region RegionOne placement internal http://10.10.35.122:8778
openstack endpoint create --region RegionOne placement admin http://10.10.35.122:8778
```

Cài đặt placement

```
yum install -y openstack-placement-api
```

Cấu hình placement

```
crudini --set  /etc/placement/placement.conf placement_database connection mysql+pymysql://placement:Welcome123@10.10.35.122/placement
crudini --set  /etc/placement/placement.conf api auth_strategy keystone
crudini --set  /etc/placement/placement.conf keystone_authtoken auth_url  http://10.10.35.122:5000/v3
crudini --set  /etc/placement/placement.conf keystone_authtoken memcached_servers 10.10.35.122:11211
crudini --set  /etc/placement/placement.conf keystone_authtoken auth_type password
crudini --set  /etc/placement/placement.conf keystone_authtoken project_domain_name Default
crudini --set  /etc/placement/placement.conf keystone_authtoken user_domain_name Default
crudini --set  /etc/placement/placement.conf keystone_authtoken project_name service
crudini --set  /etc/placement/placement.conf keystone_authtoken username placement
crudini --set  /etc/placement/placement.conf keystone_authtoken password Welcome123
```

Khai báo phân quyền cho placement

```
cat <<EOF>> /etc/httpd/conf.d/00-nova-placement-api.conf
<Directory /usr/bin>
   <IfVersion >= 2.4>
      Require all granted
   </IfVersion>
   <IfVersion < 2.4>
      Order allow,deny
      Allow from all
   </IfVersion>
</Directory>
EOF
```

Import database cho placement

```
su -s /bin/sh -c "placement-manage db sync" placement
```

Khởi động lại httpd

```
systemctl restart httpd
```

#### 2.10 Cài đặt Nova

**2.10.1 Cài đặt nova trên controller**

Tạo database và user cho nova

```
mysql -uroot -pWelcome123

CREATE DATABASE nova_api;
GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'10.10.35.122' IDENTIFIED BY 'Welcome123';

CREATE DATABASE nova;
GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'10.10.35.122' IDENTIFIED BY 'Welcome123';

CREATE DATABASE nova_cell0;
GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'10.10.35.122' IDENTIFIED BY 'Welcome123';
FLUSH PRIVILEGES;

exit
```

Thực thi biến môi trường

```
source /root/admin-openrc
```

Tạo endpoint cho nova

```
openstack user create nova --domain default --password Welcome123
openstack role add --project service --user nova admin
openstack service create --name nova --description "OpenStack Compute" compute
openstack endpoint create --region RegionOne compute public http://10.10.35.122:8774/v2.1
openstack endpoint create --region RegionOne compute internal http://10.10.35.122:8774/v2.1
openstack endpoint create --region RegionOne compute admin http://10.10.35.122:8774/v2.1
```

Cài đặt nova

```
yum install -y openstack-nova-api openstack-nova-conductor openstack-nova-novncproxy openstack-nova-scheduler
```

Cấu hình cho nova

```
crudini --set /etc/nova/nova.conf DEFAULT my_ip 10.10.35.122
crudini --set /etc/nova/nova.conf DEFAULT use_neutron true
crudini --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver
crudini --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata
crudini --set /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:Welcome123@10.10.35.122:5672/

crudini --set /etc/nova/nova.conf api_database connection mysql+pymysql://nova:Welcome123@10.10.35.122/nova_api
crudini --set /etc/nova/nova.conf database connection mysql+pymysql://nova:Welcome123@10.10.35.122/nova
crudini --set /etc/nova/nova.conf api connection  mysql+pymysql://nova:Welcome123@10.10.35.122/nova

crudini --set /etc/nova/nova.conf keystone_authtoken www_authenticate_uri http://10.10.35.122:5000/
crudini --set /etc/nova/nova.conf keystone_authtoken auth_url http://10.10.35.122:5000/
crudini --set /etc/nova/nova.conf keystone_authtoken memcached_servers 10.10.35.122:11211
crudini --set /etc/nova/nova.conf keystone_authtoken auth_type password
crudini --set /etc/nova/nova.conf keystone_authtoken project_domain_name Default
crudini --set /etc/nova/nova.conf keystone_authtoken user_domain_name Default
crudini --set /etc/nova/nova.conf keystone_authtoken project_name service
crudini --set /etc/nova/nova.conf keystone_authtoken username nova
crudini --set /etc/nova/nova.conf keystone_authtoken password Welcome123

crudini --set /etc/nova/nova.conf vnc enabled true 
crudini --set /etc/nova/nova.conf vnc server_listen \$my_ip
crudini --set /etc/nova/nova.conf vnc server_proxyclient_address \$my_ip

crudini --set /etc/nova/nova.conf glance api_servers http://10.10.35.122:9292

crudini --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp

crudini --set /etc/nova/nova.conf placement region_name RegionOne
crudini --set /etc/nova/nova.conf placement project_domain_name Default
crudini --set /etc/nova/nova.conf placement project_name service
crudini --set /etc/nova/nova.conf placement auth_type password
crudini --set /etc/nova/nova.conf placement user_domain_name Default
crudini --set /etc/nova/nova.conf placement auth_url http://10.10.35.122:5000/v3
crudini --set /etc/nova/nova.conf placement username placement
crudini --set /etc/nova/nova.conf placement password Welcome123

crudini --set /etc/nova/nova.conf scheduler discover_hosts_in_cells_interval 300

crudini --set /etc/nova/nova.conf neutron url http://10.10.35.122:9696
crudini --set /etc/nova/nova.conf neutron auth_url http://10.10.35.122:5000
crudini --set /etc/nova/nova.conf neutron auth_type password
crudini --set /etc/nova/nova.conf neutron project_domain_name Default
crudini --set /etc/nova/nova.conf neutron user_domain_name Default
crudini --set /etc/nova/nova.conf neutron project_name service
crudini --set /etc/nova/nova.conf neutron username neutron
crudini --set /etc/nova/nova.conf neutron password Welcome123
crudini --set /etc/nova/nova.conf neutron service_metadata_proxy True
crudini --set /etc/nova/nova.conf neutron metadata_proxy_shared_secret Welcome123
```

Tạo database cho nova

```
su -s /bin/sh -c "nova-manage api_db sync" nova
su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova
su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova
su -s /bin/sh -c "nova-manage db sync" nova
```

Xác nhận lại xem CELL0 đã được đăng ký hay chưa

```
su -s /bin/sh -c "nova-manage cell_v2 list_cells" nova
```

Màn hình sẽ xuất hiện kết quả

```
+-------+--------------------------------------+--------------------------------------------+---------------------------------------------------+----------+
|  Name |                 UUID                 |               Transport URL                |                Database Connection                | Disabled |
+-------+--------------------------------------+--------------------------------------------+---------------------------------------------------+----------+
| cell0 | 00000000-0000-0000-0000-000000000000 |                   none:/                   | mysql+pymysql://nova:****@10.10.35.122/nova_cell0 |  False   |
| cell1 | 425797ea-22c7-4cfb-8400-e1e56e273882 | rabbit://openstack:****@10.10.35.122:5672/ |    mysql+pymysql://nova:****@10.10.35.122/nova    |  False   |
+-------+--------------------------------------+--------------------------------------------+---------------------------------------------------+----------+
```

Enable nova

```
systemctl enable \
openstack-nova-api.service \
openstack-nova-scheduler.service \
openstack-nova-conductor.service \
openstack-nova-novncproxy.service
```

Khởi động nova

```
systemctl start \
openstack-nova-api.service \
openstack-nova-scheduler.service \
openstack-nova-conductor.service \
openstack-nova-novncproxy.service
```

Kiểm tra lại xem dịch vụ của nova đã hoạt động hay chưa.

```
openstack compute service list
```

Kết quả như sau

```
+----+----------------+------------+----------+---------+-------+----------------------------+
| ID | Binary         | Host       | Zone     | Status  | State | Updated At                 |
+----+----------------+------------+----------+---------+-------+----------------------------+
|  4 | nova-conductor | controller | internal | enabled | up    | 2020-06-24T07:37:52.000000 |
|  5 | nova-scheduler | controller | internal | enabled | up    | 2020-06-24T07:37:55.000000 |
+----+----------------+------------+----------+---------+-------+----------------------------+
```

**2.10.2 Cài đặt nova trên node compute1**

Cài đặt các gói của nova

```
yum install -y python-openstackclient openstack-selinux openstack-utils
yum install -y openstack-nova-compute
```

Sao lưu file cấu hình của nova

```
cp  /etc/nova/nova.conf  /etc/nova/nova.conf.bak
```

Cấu hình nova

```
crudini --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata
crudini --set /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:Welcome123@10.10.35.122
crudini --set /etc/nova/nova.conf DEFAULT my_ip 10.10.35.123
crudini --set /etc/nova/nova.conf DEFAULT use_neutron true
crudini --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver

crudini --set /etc/nova/nova.conf api_database connection mysql+pymysql://nova:Welcome123@10.10.35.122/nova_api

crudini --set /etc/nova/nova.conf database connection mysql+pymysql://nova:Welcome123@10.10.35.122/nova

crudini --set /etc/nova/nova.conf api auth_strategy keystone

crudini --set /etc/nova/nova.conf keystone_authtoken www_authenticate_uri http://10.10.35.122:5000/
crudini --set /etc/nova/nova.conf keystone_authtoken auth_url http://10.10.35.122:5000/
crudini --set /etc/nova/nova.conf keystone_authtoken memcached_servers 10.10.35.122:11211
crudini --set /etc/nova/nova.conf keystone_authtoken auth_type password
crudini --set /etc/nova/nova.conf keystone_authtoken project_domain_name Default
crudini --set /etc/nova/nova.conf keystone_authtoken user_domain_name Default
crudini --set /etc/nova/nova.conf keystone_authtoken project_name service
crudini --set /etc/nova/nova.conf keystone_authtoken username nova
crudini --set /etc/nova/nova.conf keystone_authtoken password Welcome123

crudini --set /etc/nova/nova.conf vnc enabled true
crudini --set /etc/nova/nova.conf vnc server_listen 0.0.0.0
crudini --set /etc/nova/nova.conf vnc server_proxyclient_address \$my_ip
crudini --set /etc/nova/nova.conf vnc novncproxy_base_url http://10.10.35.122:6080/vnc_auto.html

crudini --set /etc/nova/nova.conf glance api_servers http://10.10.35.122:9292

crudini --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp

crudini --set /etc/nova/nova.conf placement region_name RegionOne
crudini --set /etc/nova/nova.conf placement project_domain_name Default
crudini --set /etc/nova/nova.conf placement project_name service
crudini --set /etc/nova/nova.conf placement auth_type password
crudini --set /etc/nova/nova.conf placement user_domain_name Default
crudini --set /etc/nova/nova.conf placement auth_url http://10.10.35.122:5000/v3
crudini --set /etc/nova/nova.conf placement username placement
crudini --set /etc/nova/nova.conf placement password Welcome123

crudini --set /etc/nova/nova.conf libvirt virt_type  $(count=$(egrep -c '(vmx|svm)' /proc/cpuinfo); if [ $count -eq 0 ];then   echo "qemu"; else   echo "kvm"; fi)
```

Khởi động lại nova

```
systemctl enable libvirtd.service openstack-nova-compute.service
systemctl start libvirtd.service openstack-nova-compute.service
```

**2.10.3 Cài đặt nova trên node compute2**

Làm tương tự như node compute1 nhưng thay đổi địa chỉ `my_ip` thành địa chỉ IP của `compute2`

**2.10.4 Thêm node compute vào hệ thống**

> Thực hiện trên node controller

Kiểm tra trạng thái của compute1 và compute2 trên computer

```
source /root/admin-openrc
openstack compute service list --service nova-compute
```

Kết quả ta sẽ thấy như bên dưới là ok.

```
+----+--------------+----------+------+---------+-------+----------------------------+
| ID | Binary       | Host     | Zone | Status  | State | Updated At                 |
+----+--------------+----------+------+---------+-------+----------------------------+
|  6 | nova-compute | compute1 | nova | enabled | up    | 2020-06-24T08:01:25.000000 |
|  7 | nova-compute | compute2 | nova | enabled | up    | 2020-06-24T08:08:11.000000 |
+----+--------------+----------+------+---------+-------+----------------------------+
```

Thực hiện add node `compute` vào CELL

```
su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova
```

#### 2.11 Cài đặt Neutron

**2.11.1 Cài đặt neutron trên node controller**

Tạo database cho neutron

```
mysql -uroot -pWelcome123
CREATE DATABASE neutron;
GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'10.10.35.122' IDENTIFIED BY 'Welcome123';
FLUSH PRIVILEGES;
exit
```

Tạo project, user, endpoint cho neutron

```
source /root/admin-openrc
openstack user create neutron --domain default --password Welcome123
openstack role add --project service --user neutron admin
openstack service create --name neutron --description "OpenStack Compute" network
openstack endpoint create --region RegionOne network public http://10.10.35.122:9696
openstack endpoint create --region RegionOne network internal http://10.10.35.122:9696
openstack endpoint create --region RegionOne network admin http://10.10.35.122:9696
```

Cài đặt neutron

```
yum install -y openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables
```

Sao lưu file cấu hình của neutron

```
cp  /etc/neutron/neutron.conf  /etc/neutron/neutron.conf.bak
cp /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugins/ml2/ml2_conf.ini.bak
cp  /etc/neutron/plugins/ml2/linuxbridge_agent.ini  /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak 
cp /etc/neutron/dhcp_agent.ini /etc/neutron/dhcp_agent.ini.bak
cp /etc/neutron/metadata_agent.ini /etc/neutron/metadata_agent.ini.bak
```

Cấu hình file `/etc/neutron/neutron.conf`

```
crudini --set  /etc/neutron/neutron.conf DEFAULT core_plugin ml2
crudini --set  /etc/neutron/neutron.conf DEFAULT service_plugins router
crudini --set  /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:Welcome123@10.10.35.122
crudini --set  /etc/neutron/neutron.conf DEFAULT auth_strategy keystone
crudini --set  /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_status_changes True
crudini --set  /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_data_changes True 

crudini --set  /etc/neutron/neutron.conf database connection  mysql+pymysql://neutron:Welcome123@10.10.35.122/neutron

crudini --set  /etc/neutron/neutron.conf keystone_authtoken www_authenticate_uri http://10.10.35.122:5000
crudini --set  /etc/neutron/neutron.conf keystone_authtoken auth_url http://10.10.35.122:5000
crudini --set  /etc/neutron/neutron.conf keystone_authtoken memcached_servers 10.10.35.122:11211
crudini --set  /etc/neutron/neutron.conf keystone_authtoken auth_type password
crudini --set  /etc/neutron/neutron.conf keystone_authtoken project_domain_name default
crudini --set  /etc/neutron/neutron.conf keystone_authtoken user_domain_name default
crudini --set  /etc/neutron/neutron.conf keystone_authtoken project_name service
crudini --set  /etc/neutron/neutron.conf keystone_authtoken username neutron
crudini --set  /etc/neutron/neutron.conf keystone_authtoken password Welcome123

crudini --set /etc/neutron/neutron.conf nova auth_url http://10.10.35.122:5000
crudini --set /etc/neutron/neutron.conf nova auth_type password
crudini --set /etc/neutron/neutron.conf nova project_domain_name Default
crudini --set /etc/neutron/neutron.conf nova user_domain_name Default
crudini --set /etc/neutron/neutron.conf nova region_name RegionOne
crudini --set /etc/neutron/neutron.conf nova project_name service
crudini --set /etc/neutron/neutron.conf nova username nova
crudini --set /etc/neutron/neutron.conf nova password Welcome123
crudini --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp
```

Sửa file cấu hình của `/etc/neutron/plugins/ml2/ml2_conf.ini`

```
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers flat,vlan,vxlan
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types vxlan
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers linuxbridge
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 extension_drivers port_security          
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_flat flat_networks provider
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vxlan vni_ranges 1:1000        
crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_ipset True
```

Sửa file `/etc/neutron/plugins/ml2/linuxbridge_agent.ini`

```
crudini --set  /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth1
crudini --set  /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan True
crudini --set  /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan local_ip $(ip addr show dev eth2 scope global | grep "inet " | sed -e 's#.*inet ##g' -e 's#/.*##g')
crudini --set  /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group True
crudini --set  /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
```

Khai báo `sysctl`

```
echo 'net.bridge.bridge-nf-call-iptables = 1' >> /etc/sysctl.conf
echo 'net.bridge.bridge-nf-call-ip6tables = 1' >> /etc/sysctl.conf
modprobe br_netfilter
/sbin/sysctl -p
```

Tạo liên kết

```
ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
```

Thiết lập database

```
su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf \
--config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron
```

Khởi động và kích hoạt neutron

```
systemctl enable neutron-server.service \
neutron-linuxbridge-agent.service neutron-dhcp-agent.service \
neutron-metadata-agent.service
  
systemctl start neutron-server.service \
neutron-linuxbridge-agent.service neutron-dhcp-agent.service \
neutron-metadata-agent.service
```

**2.11.2 Cài đặt neutron trên node compute**

> Thực hiện trên cả 2 node compute

Khai báo bổ sung cho nova

```
crudini --set /etc/nova/nova.conf neutron url http://10.10.35.122:9696
crudini --set /etc/nova/nova.conf neutron auth_url http://10.10.35.122:5000
crudini --set /etc/nova/nova.conf neutron auth_type password
crudini --set /etc/nova/nova.conf neutron project_domain_name Default
crudini --set /etc/nova/nova.conf neutron user_domain_name Default
crudini --set /etc/nova/nova.conf neutron project_name service
crudini --set /etc/nova/nova.conf neutron username neutron
crudini --set /etc/nova/nova.conf neutron password Welcome123
```

Cài đặt neutron

```
yum install -y openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables ipset
```

Sao lưu cấu hình neutron

```
cp /etc/neutron/neutron.conf /etc/neutron/neutron.conf.bak
cp /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugins/ml2/ml2_conf.ini.bak
cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak
cp /etc/neutron/dhcp_agent.ini /etc/neutron/dhcp_agent.ini.bak
cp /etc/neutron/metadata_agent.ini /etc/neutron/metadata_agent.ini.bak
```

Sửa cấu hình neutron

```
crudini --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone
crudini --set /etc/neutron/neutron.conf DEFAULT core_plugin ml2
crudini --set /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:Welcome123@10.10.35.122
crudini --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_status_changes true
crudini --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_data_changes true

crudini --set /etc/neutron/neutron.conf keystone_authtoken www_authenticate_uri http://10.10.35.122:5000
crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://10.10.35.122:5000
crudini --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers 10.10.35.122:11211
crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_type password
crudini --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name Default
crudini --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name Default
crudini --set /etc/neutron/neutron.conf keystone_authtoken project_name service
crudini --set /etc/neutron/neutron.conf keystone_authtoken username neutron
crudini --set /etc/neutron/neutron.conf keystone_authtoken password Welcome123

crudini --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp
```

Khai báo `sysctl`

```
echo 'net.bridge.bridge-nf-call-iptables = 1' >> /etc/sysctl.conf
echo 'net.bridge.bridge-nf-call-ip6tables = 1' >> /etc/sysctl.conf
modprobe br_netfilter
/sbin/sysctl -p
```

Sửa file `/etc/neutron/plugins/ml2/linuxbridge_agent.ini`

```
crudini --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth1
crudini --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan True
crudini --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan local_ip $(ip addr show dev eth2 scope global | grep "inet " | sed -e 's#.*inet ##g' -e 's#/.*##g')
crudini --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group True
crudini --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
```

Khai báo cho file `/etc/neutron/metadata_agent.ini`

```
crudini --set /etc/neutron/metadata_agent.ini DEFAULT nova_metadata_host 10.10.35.122
crudini --set /etc/neutron/metadata_agent.ini DEFAULT metadata_proxy_shared_secret Welcome123
```

Khai báo cho file `/etc/neutron/dhcp_agent.ini`

```
crudini --set /etc/neutron/dhcp_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.BridgeInterfaceDriver
crudini --set /etc/neutron/dhcp_agent.ini DEFAULT enable_isolated_metadata True
crudini --set /etc/neutron/dhcp_agent.ini DEFAULT dhcp_driver neutron.agent.linux.dhcp.Dnsmasq
crudini --set /etc/neutron/dhcp_agent.ini DEFAULT force_metadata True
```

Kích hoạt neutron

```
systemctl enable neutron-linuxbridge-agent.service
systemctl enable neutron-metadata-agent.service
systemctl enable neutron-dhcp-agent.service
```

Khởi động neutron

```
systemctl start neutron-linuxbridge-agent.service
systemctl start neutron-metadata-agent.service
systemctl start neutron-dhcp-agent.service
systemctl restart openstack-nova-compute.service
```

#### 2.12 Cài đặt horizon trên controller

Cài đặt dashboard cho Openstack

```
yum install -y openstack-dashboard
```

Sao lưu file `/etc/openstack-dashboard/local_settings`

```
cp /etc/openstack-dashboard/local_settings /etc/openstack-dashboard/local_settings.bak
```

Tải file cấu hình mẫu

```
wget -O /etc/openstack-dashboard/local_settings https://gist.githubusercontent.com/congto/5b5b73a64b90f403966ae70a5394d650/raw/8321ebbd73de47d19f836e1383224cf9c71f291c/local_settings

chown root:apache /etc/openstack-dashboard/local_settings
```

Sau khi tải về, sửa IP về IP của node controller: 10.10.35.122

Thực hiện các lếnh sau

```
cd /usr/share/openstack-dashboard

python manage.py make_web_conf --apache > /etc/httpd/conf.d/openstack-dashboard.conf

ln -s /etc/openstack-dashboard /usr/share/openstack-dashboard/openstack_dashboard/conf

systemctl enable httpd.service

systemctl restart httpd.service
 
systemctl restart memcached.service
```

Truy cập địa chỉ `http://10.10.35.122` với user/pass: `admin`/`Welcome123`

#### 2.13 Cài đặt Cinder trên controller

Tạo database

```
mysql -u root -pWelcome123
CREATE DATABASE cinder;
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' IDENTIFIED BY 'Welcome123';
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' IDENTIFIED BY 'Welcome123';
```

Tạo user

```
source /root/admin-openrc

openstack user create --domain default --password Welcome123 cinder
```

Add role

```
openstack role add --project service --user cinder admin
```

Tạo service

```
openstack service create --name cinderv2 \
--description "OpenStack Block Storage" volumev2

openstack service create --name cinderv3 \
--description "OpenStack Block Storage" volumev3
```

Tạo endpoint

```
openstack endpoint create --region RegionOne \
volumev2 public http://10.10.35.122:8776/v2/%\(project_id\)s

openstack endpoint create --region RegionOne \
volumev2 internal http://10.10.35.122:8776/v2/%\(project_id\)s

openstack endpoint create --region RegionOne \
volumev2 admin http://10.10.35.122:8776/v2/%\(project_id\)s

openstack endpoint create --region RegionOne \
volumev3 public http://10.10.35.122:8776/v3/%\(project_id\)s

openstack endpoint create --region RegionOne \
volumev3 internal http://10.10.35.122:8776/v3/%\(project_id\)s

openstack endpoint create --region RegionOne \
volumev3 admin http://10.10.35.122:8776/v3/%\(project_id\)s
```

Cài đặt Cinder

```
yum install -y openstack-cinder lvm2 device-mapper-persistent-data targetcli python-keystone
```

Enable service

```
systemctl enable lvm2-lvmetad.service
systemctl start lvm2-lvmetad.service
```

Kiểm tra dung lượng disk:

```
#lsblk
NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0              11:0    1  918M  0 rom
vda             252:0    0   60G  0 disk
├─vda1          252:1    0    1G  0 part /boot
└─vda2          252:2    0   59G  0 part
  ├─centos-root 253:0    0 35.6G  0 lvm  /
  ├─centos-swap 253:1    0    6G  0 lvm  [SWAP]
  └─centos-home 253:2    0 17.4G  0 lvm  /home
vdb             252:16   0  100G  0 disk
```

Tạo pv, vg

```
pvcreate /dev/vdb

vgcreate cinder-volumes /dev/vdb
```

Chỉnh sửa file: /etc/lvm/lvm.conf

Uncomment dòng 141

```
filter = [ "a|.*/|" ]
```

Backups cấu hình Cinder:

```
mv /etc/cinder/cinder.conf /etc/cinder/cinder.conf.bak
```

Cấu hình cinder

```
cat << EOF >> /etc/cinder/cinder.conf
[DEFAULT]
transport_url = rabbit://openstack:Welcome123@10.10.35.122
auth_strategy = keystone
my_ip = 10.10.35.122
enabled_backends = lvm
glance_api_servers = http://10.10.35.122:9292
enable_v3_api = True
[backend]
[backend_defaults]
[barbican]
[brcd_fabric_example]
[cisco_fabric_example]
[coordination]
[cors]
[database]
connection = mysql+pymysql://cinder:Welcome123@10.10.35.122/cinder
[fc-zone-manager]
[healthcheck]
[key_manager]
[keystone_authtoken]
www_authenticate_uri = http://10.10.35.122:5000
auth_url = http://10.10.35.122:5000
memcached_servers = 10.10.35.122:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = Welcome123
[nova]
[oslo_concurrency]
lock_path = /var/lib/cinder/tmp
[oslo_messaging_amqp]
[oslo_messaging_kafka]
[oslo_messaging_notifications]
[oslo_messaging_rabbit]
[oslo_middleware]
[oslo_policy]
[oslo_reports]
[oslo_versionedobjects]
[privsep]
[profiler]
[sample_castellan_source]
[sample_remote_file_source]
[service_user]
[ssl]
[vault]
[lvm]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_group = cinder-volumes
target_protocol = iscsi
target_helper = lioadm
EOF
```

Import database cho cinder

```
su -s /bin/sh -c "cinder-manage db sync" cinder
```

Restart nova-api

```
systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service openstack-cinder-volume.service target.service

systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service openstack-cinder-volume.service target.service
```

Kiểm tra lại

```
openstack volume service list

+------------------+----------------+------+---------+-------+----------------------------+
| Binary           | Host           | Zone | Status  | State | Updated At                 |
+------------------+----------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller     | nova | enabled | up    | 2020-07-29T02:31:29.000000 |
| cinder-volume    | controller@lvm | nova | enabled | up    | 2020-07-29T02:31:30.000000 |
+------------------+----------------+------+---------+-------+----------------------------+
```

### 3. Cấu hình cinder-backup ra NFS

